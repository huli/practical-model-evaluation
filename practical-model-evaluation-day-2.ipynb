{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These notebooks are part of Kaggle’s [Practical Model Evaluation](https://www.kaggle.com/practical-model-evaluation) event, which ran from December 3-5 2019. You can find the [livestreams for this event here](https://youtu.be/7RdKnACscjA?list=PLqFaTIg4myu-HA1VGJi_7IGFkKRoZeOFt).\n",
    "\n",
    "* Day 1 Notebook: [Figuring out what matters for you](https://www.kaggle.com/rtatman/practical-model-evaluation-day-1)\n",
    "* Day 2 Notebook: [Training models with automated machine learning](https://www.kaggle.com/rtatman/practical-model-evaluation-day-2)\n",
    "* Day 3 Notebook: [Evaluating our models](https://www.kaggle.com/rtatman/practical-model-evaluation-day-3)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For today's exercise, we're going to be working on classifying roles into job titles based on information about the role. The data will be from the [2018](https://www.kaggle.com/kaggle/kaggle-survey-2018) and [2019](https://www.kaggle.com/c/kaggle-survey-2019) Kaggle data science survey. \n",
    "\n",
    "I've already [done some data cleaning](https://www.kaggle.com/rebeccaturner/data-prep-for-job-title-classification) but if you'd like to do your own or do some additional feature engineering, feel free!\n",
    "\n",
    "Today we'll be building four different models using four different libraries, including some automated machine learning libraries. \n",
    "\n",
    "> Automated machine learning (or AutoML for short) is the task of removing human labor from the process of training machine learning models. Currently most AutoML research is focused on automating model selection and hyperparameter tuning. [This video](https://www.youtube.com/watch?v=Rsg_XzgGqZw&utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event) goes into more details.\n",
    "\n",
    "The libraries we'll be using are:\n",
    "\n",
    "* [XGBoost](https://xgboost.readthedocs.io/en/latest/) (not automated machine learning: we'll be using this as a baseline)\n",
    "* [Cloud AutoML](https://cloud.google.com/automl/?utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event), an enterprise-focused automated machine learning product\n",
    "* [TPOT](https://epistasislab.github.io/tpot/), an open source automated machine learning library developed at the University of Pennsylvania\n",
    "* [H20.ai AutoML](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html), a second open source automated machine learning library developed by researchers at H20.ai\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data\n",
    "\n",
    "First let's load in our pre-cleaned data. I'll be using the 2018 data as an example and then have you work through the 2019 data as your exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import category_encoders as ce\n",
    "\n",
    "# set a seed for reproducability\n",
    "random.seed(42)\n",
    "\n",
    "# read in our data\n",
    "df_2018 = pd.read_csv(\"data/cleaned/data_jobs_info_2018.csv\")\n",
    "df_2019 = pd.read_csv(\"data/cleaned/data_jobs_info_2019.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "We do have an additional step of preperation. First, we'll split into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into predictor & target variables\n",
    "X = df_2018.drop(\"job_title\", axis=1)\n",
    "y = df_2018[\"job_title\"]\n",
    "\n",
    "# Splitting data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, test_size=0.20)\n",
    "\n",
    "# save out the split training data to use with Cloud AutoML\n",
    "with open(\"data/model_input/train_data_2018.csv\", \"+w\") as file:\n",
    "    pd.concat([X_train, y_train], axis=1).to_csv(file, index=False)\n",
    "with open(\"data/model_input/test_data_2018.csv\", \"+w\") as file:\n",
    "    pd.concat([X_test, y_test], axis=1).to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For H20 AutoML and Cloud AutoML we don't need to do anything else. (Actually for Cloud AutoML we don't even need to split our data, but we'll look at that in a minute.) \n",
    "\n",
    "For TPOT and XGBoost, however, we need to make sure that all our input data is numeric. We'll be using [ordinal label encoding](https://contrib.scikit-learn.org/categorical-encoding/ordinal.html) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyze_and_understand_data_to_influence_product_or_business_decisions</th>\n",
       "      <th>build_a_machine_learning_service_that_operationally_improves_my_product_or_workflows</th>\n",
       "      <th>build_the_data_infrastructure_that_my_business_uses_for_storing_analyzing_and_operationalizing_data</th>\n",
       "      <th>build_prototypes_to_explore_applying_machine_learning_to_new_areas</th>\n",
       "      <th>do_research_that_advances_the_state_of_the_art_of_machine_learning</th>\n",
       "      <th>none_of_these_activities_are_an_important_part_of_my_role_at_work</th>\n",
       "      <th>what_is_the_primary_tool_that_you_use_at_work_or_school_to_analyze_data</th>\n",
       "      <th>google_cloud_platform_gcp</th>\n",
       "      <th>amazon_web_services_aws</th>\n",
       "      <th>microsoft_azure</th>\n",
       "      <th>...</th>\n",
       "      <th>text_data</th>\n",
       "      <th>time_series_data</th>\n",
       "      <th>video_data</th>\n",
       "      <th>highest_level_of_formal_education</th>\n",
       "      <th>current_industry</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>yearly_compensation</th>\n",
       "      <th>does_your_current_employer_incorporate_machine_learning_methods_into_their_business</th>\n",
       "      <th>which_ml_library_have_you_used_the_most_selected_choice</th>\n",
       "      <th>what_percent_of_your_time_at_work_is_spent_actively_coding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyze and understand data to influence produ...</td>\n",
       "      <td>Build and/or run a machine learning service th...</td>\n",
       "      <td>Build and/or run the data infrastructure that ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Do research that advances the state of the art...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cloud-based data software &amp; APIs (AWS, GCP, Az...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Microsoft Azure</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Doctoral degree</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0% of my time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  analyze_and_understand_data_to_influence_product_or_business_decisions  \\\n",
       "0  Analyze and understand data to influence produ...                       \n",
       "\n",
       "  build_a_machine_learning_service_that_operationally_improves_my_product_or_workflows  \\\n",
       "0  Build and/or run a machine learning service th...                                     \n",
       "\n",
       "  build_the_data_infrastructure_that_my_business_uses_for_storing_analyzing_and_operationalizing_data  \\\n",
       "0  Build and/or run the data infrastructure that ...                                                    \n",
       "\n",
       "  build_prototypes_to_explore_applying_machine_learning_to_new_areas  \\\n",
       "0                                                NaN                   \n",
       "\n",
       "  do_research_that_advances_the_state_of_the_art_of_machine_learning  \\\n",
       "0  Do research that advances the state of the art...                   \n",
       "\n",
       "  none_of_these_activities_are_an_important_part_of_my_role_at_work  \\\n",
       "0                                                NaN                  \n",
       "\n",
       "  what_is_the_primary_tool_that_you_use_at_work_or_school_to_analyze_data  \\\n",
       "0  Cloud-based data software & APIs (AWS, GCP, Az...                        \n",
       "\n",
       "  google_cloud_platform_gcp amazon_web_services_aws  microsoft_azure  ...  \\\n",
       "0                       NaN                     NaN  Microsoft Azure  ...   \n",
       "\n",
       "  text_data time_series_data video_data highest_level_of_formal_education  \\\n",
       "0       NaN              NaN        NaN                   Doctoral degree   \n",
       "\n",
       "  current_industry years_of_experience yearly_compensation  \\\n",
       "0            Other                 NaN                 NaN   \n",
       "\n",
       "  does_your_current_employer_incorporate_machine_learning_methods_into_their_business  \\\n",
       "0                                      I do not know                                    \n",
       "\n",
       "  which_ml_library_have_you_used_the_most_selected_choice  \\\n",
       "0                                                NaN        \n",
       "\n",
       "  what_percent_of_your_time_at_work_is_spent_actively_coding  \n",
       "0                                      0% of my time          \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode all features using ordinal encoding\n",
    "encoder_x = ce.OrdinalEncoder()\n",
    "X_encoded = encoder_x.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyze_and_understand_data_to_influence_product_or_business_decisions</th>\n",
       "      <th>build_a_machine_learning_service_that_operationally_improves_my_product_or_workflows</th>\n",
       "      <th>build_the_data_infrastructure_that_my_business_uses_for_storing_analyzing_and_operationalizing_data</th>\n",
       "      <th>build_prototypes_to_explore_applying_machine_learning_to_new_areas</th>\n",
       "      <th>do_research_that_advances_the_state_of_the_art_of_machine_learning</th>\n",
       "      <th>none_of_these_activities_are_an_important_part_of_my_role_at_work</th>\n",
       "      <th>what_is_the_primary_tool_that_you_use_at_work_or_school_to_analyze_data</th>\n",
       "      <th>google_cloud_platform_gcp</th>\n",
       "      <th>amazon_web_services_aws</th>\n",
       "      <th>microsoft_azure</th>\n",
       "      <th>...</th>\n",
       "      <th>text_data</th>\n",
       "      <th>time_series_data</th>\n",
       "      <th>video_data</th>\n",
       "      <th>highest_level_of_formal_education</th>\n",
       "      <th>current_industry</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>yearly_compensation</th>\n",
       "      <th>does_your_current_employer_incorporate_machine_learning_methods_into_their_business</th>\n",
       "      <th>which_ml_library_have_you_used_the_most_selected_choice</th>\n",
       "      <th>what_percent_of_your_time_at_work_is_spent_actively_coding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   analyze_and_understand_data_to_influence_product_or_business_decisions  \\\n",
       "0                                                  1                        \n",
       "\n",
       "   build_a_machine_learning_service_that_operationally_improves_my_product_or_workflows  \\\n",
       "0                                                  1                                      \n",
       "\n",
       "   build_the_data_infrastructure_that_my_business_uses_for_storing_analyzing_and_operationalizing_data  \\\n",
       "0                                                  1                                                     \n",
       "\n",
       "   build_prototypes_to_explore_applying_machine_learning_to_new_areas  \\\n",
       "0                                                  1                    \n",
       "\n",
       "   do_research_that_advances_the_state_of_the_art_of_machine_learning  \\\n",
       "0                                                  1                    \n",
       "\n",
       "   none_of_these_activities_are_an_important_part_of_my_role_at_work  \\\n",
       "0                                                  1                   \n",
       "\n",
       "   what_is_the_primary_tool_that_you_use_at_work_or_school_to_analyze_data  \\\n",
       "0                                                  1                         \n",
       "\n",
       "   google_cloud_platform_gcp  amazon_web_services_aws  microsoft_azure  ...  \\\n",
       "0                          1                        1                1  ...   \n",
       "\n",
       "   text_data  time_series_data  video_data  highest_level_of_formal_education  \\\n",
       "0          1                 1           1                                  1   \n",
       "\n",
       "   current_industry  years_of_experience  yearly_compensation  \\\n",
       "0                 1                    1                    1   \n",
       "\n",
       "   does_your_current_employer_incorporate_machine_learning_methods_into_their_business  \\\n",
       "0                                                  1                                     \n",
       "\n",
       "   which_ml_library_have_you_used_the_most_selected_choice  \\\n",
       "0                                                  1         \n",
       "\n",
       "   what_percent_of_your_time_at_work_is_spent_actively_coding  \n",
       "0                                                  1           \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you'll need to use a different encoder for each dataframe\n",
    "encoder_y = ce.OrdinalEncoder()\n",
    "y_encoded = encoder_y.fit_transform(y)\n",
    "\n",
    "# split encoded dataset\n",
    "X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(X_encoded, y_encoded,\n",
    "                                                    train_size=0.80, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Baseline\n",
    "\n",
    "First, we're going to train a basic XGBoost model using the default arguments. We cover XGBoost in more detail in the [Intro To Machine Learning course](https://www.kaggle.com/learn/intro-to-machine-learning), so I'm not going to talk about it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chhilty/Source/practical-model-evaluation/env/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/chhilty/Source/practical-model-evaluation/env/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# train XGBoost model with default parameters\n",
    "my_model = XGBClassifier()\n",
    "my_model.fit(X_train_encoded, y_train_encoded, verbose=False)\n",
    "\n",
    "# and save our model\n",
    "my_model.save_model(\"xgboost_baseline.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4864767399927876"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see what our baseline model is offering\n",
    "my_model.score(X_test_encoded, y_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud AutoML\n",
    "\n",
    "Now let's train our Cloud AutoML model! We'll be using both the GCP console and notebook code here, so you'll probably want to open those in separate tabs or windows.\n",
    "\n",
    "### Prepare your account and project\n",
    "\n",
    "\n",
    "* First you’ll need to [create a GCP account](https://accounts.google.com/signup/v2/webcreateaccount?service=cloudconsole&continue=https%3A%2F%2Fconsole.cloud.google.com%2F&dsh=S-385463669%3A1575309184770524&gmb=exp&biz=false&flowName=GlifWebSignIn&flowEntry=SignUp&nogm=true&utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event) (if you already have a Google account you can use that one) and [enable billing](https://www.youtube.com/watch?v=uINleRduCWM&utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event).\n",
    "\n",
    "\n",
    "> For now, you do need to have a credit card in order to enable billing and you need billing enabled to use Cloud AutoML. If you’re not able to enable billing you can still follow along with the rest of the workshop, just skip the Cloud AutoML parts. \n",
    "\n",
    " \n",
    "\n",
    "* From there, [create a new project](https://cloud.google.com/appengine/docs/standard/nodejs/building-app/creating-project?utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event). You should [set the region of your project](https://cloud.google.com/compute/docs/regions-zones/?utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event) to “us-central1”.\n",
    "\n",
    "* Go to the [AutoML Tables](https://console.cloud.google.com/automl-tables?utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event) page in the Google Cloud Console and click *enable API*. This will let you train an AutoML Tables model in your current project. \n",
    "\n",
    "\n",
    "### Creating your dataset\n",
    "\n",
    "\n",
    "For this workshop, we’re going to create our AutoML datasets using the GCP console. The reason for this is that importing datasets can take a while. If you have the code in your notebook to import your dataset right before the code to create your model, when you run your notebook top to bottom it’ll give you an error because the modelling code was run before the dataset was done importing.\n",
    "\n",
    "\n",
    "* Click on “Datasets” in the list on the left hand side of your screen and then click on the blue **[+] New Dataset** text near the top of your screen.\n",
    "\n",
    "* Give your dataset a name and make sure the region is **US-CENTRAL1**.  \n",
    "\n",
    "* Select “Upload files from your computer” and select the file with the dataset you want. \n",
    "\n",
    "* Click on **BROWSE** under the “Select Files” button and a side panel will pop up. \n",
    "\n",
    "    * If you haven’t created any buckets you’ll see the text “No buckets found”. To create a new bucket, click on the icon that looks like a shopping basket with a plus sign in it.\n",
    "\n",
    "    * Follow the prompts to create your bucket. **Important:** Make sure in the “Choose where to store your data” step, you pick “Region” and set the location as “us-central1 (Iowa). \n",
    "\n",
    "* Select the bucket where you’d like to store your data.\n",
    "\n",
    "* Import your dataset. (This may take a while.)\n",
    "\n",
    "* Once your dataset is done importing, take a close look at your imported data and make sure it looks the way you’d expect.\n",
    "\n",
    "\n",
    "### Training our model\n",
    "\n",
    "\n",
    "In order to train an AutoML model from inside Kaggle Notebooks, you’ll need to attach a notebook to your Google Cloud Account. [This video goes into more detail](https://youtu.be/xP99eh6nQN0?utm_medium=notebook&utm_source=kaggle&utm_campaign=automl-event). \n",
    "\n",
    "\n",
    "Then you can modify the following code to start your AutoML model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "from google.cloud import automl_v1beta1 as automl\n",
    "from kaggle.gcp import KaggleKernelCredentials\n",
    "from kaggle_secrets import GcpTarget\n",
    "from google.cloud import storage\n",
    "\n",
    "# don't change this value!\n",
    "REGION = 'us-central1' # don't change: this is the only region that works currently\n",
    "\n",
    "# these you'll change based on your GCP project/data\n",
    "PROJECT_ID = 'kaggle-automl-example' # this will come from your specific GCP project\n",
    "DATASET_DISPLAY_NAME = 'data_jobs_info_2018' # name of your uploaded dataset (from GCP console)\n",
    "TARGET_COLUMN = 'job_title' # column with feature you're trying to predict\n",
    "\n",
    "# these can be whatever you like\n",
    "MODEL_DISPLAY_NAME = 'kaggle_automl_example_model' # what you want to call your model\n",
    "TRAIN_BUDGET = 1000 # max time to train model in milli-hours, from 1000-72000\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID, credentials=KaggleKernelCredentials(GcpTarget.GCS)) \n",
    "tables_gcs_client = automl.GcsClient(client=storage_client, credentials=KaggleKernelCredentials(GcpTarget.GCS)) \n",
    "tables_client = automl.TablesClient(project=PROJECT_ID, region=REGION, gcs_client=tables_gcs_client, credentials=KaggleKernelCredentials(GcpTarget.AUTOML))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/452234229115/locations/us-central1/datasets/TBL5202814255845343232\"\n",
       "display_name: \"data_jobs_info_2018\"\n",
       "create_time {\n",
       "  seconds: 1575401904\n",
       "  nanos: 806497000\n",
       "}\n",
       "etag: \"AB3BwFo5q1Fga2k13Y3rkhfmayPrJGyEQjwXFcL73vYEuzVs5XVK53PbLCmEHorp77ZA\"\n",
       "example_count: 13862\n",
       "tables_dataset_metadata {\n",
       "  primary_table_spec_id: \"5034575782656081920\"\n",
       "  target_column_spec_id: \"9148800959235751936\"\n",
       "  target_column_correlations {\n",
       "    key: \"1078350426987823104\"\n",
       "    value {\n",
       "      cramers_v: 0.02835003252597241\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"1294523209101606912\"\n",
       "    value {\n",
       "      cramers_v: 0.05767843611880267\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"1654811179291246592\"\n",
       "    value {\n",
       "      cramers_v: 0.029940460488645747\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"1943041555442958336\"\n",
       "    value {\n",
       "      cramers_v: 0.015452905323776783\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"2231271931594670080\"\n",
       "    value {\n",
       "      cramers_v: 0.01498704796962198\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"2807732683898093568\"\n",
       "    value {\n",
       "      cramers_v: 0.026341049526701674\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"3095963060049805312\"\n",
       "    value {\n",
       "      cramers_v: 0.05113002137364723\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"3384193436201517056\"\n",
       "    value {\n",
       "      cramers_v: 0.026228333569284504\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"3672423812353228800\"\n",
       "    value {\n",
       "      cramers_v: 0.050759289946223245\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"3960654188504940544\"\n",
       "    value {\n",
       "      cramers_v: 0.014786091207045333\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"4248884564656652288\"\n",
       "    value {\n",
       "      cramers_v: 0.03745949678439566\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"4537114940808364032\"\n",
       "    value {\n",
       "      cramers_v: 0.027984289925978574\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"4753287722922147840\"\n",
       "    value {\n",
       "      cramers_v: 0.03955251126873317\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"501889674684399616\"\n",
       "    value {\n",
       "      cramers_v: 0.010360098755500056\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"5113575693111787520\"\n",
       "    value {\n",
       "      cramers_v: 0.005501737941815892\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"5401806069263499264\"\n",
       "    value {\n",
       "      cramers_v: 0.02990491323748493\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"5690036445415211008\"\n",
       "    value {\n",
       "      cramers_v: 0.01480733951023409\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"5906209227528994816\"\n",
       "    value {\n",
       "      cramers_v: 0.050180324750210566\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"6266497197718634496\"\n",
       "    value {\n",
       "      cramers_v: 0.010363774712942754\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"6554727573870346240\"\n",
       "    value {\n",
       "      cramers_v: 0.026584870607957077\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"6842957950022057984\"\n",
       "    value {\n",
       "      cramers_v: 0.015852384216764638\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"7059130732135841792\"\n",
       "    value {\n",
       "      cramers_v: 0.051269547098965126\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"7419418702325481472\"\n",
       "    value {\n",
       "      cramers_v: 0.011611357384300698\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"7707649078477193216\"\n",
       "    value {\n",
       "      cramers_v: 0.05960229203419278\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"790120050836111360\"\n",
       "    value {\n",
       "      cramers_v: 0.04437117282601206\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"7995879454628904960\"\n",
       "    value {\n",
       "      cramers_v: 0.0674765679112893\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"8284109830780616704\"\n",
       "    value {\n",
       "      cramers_v: 0.045443076652998474\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"8572340206932328448\"\n",
       "    value {\n",
       "      cramers_v: 0.02821290209068001\n",
       "    }\n",
       "  }\n",
       "  target_column_correlations {\n",
       "    key: \"8860570583084040192\"\n",
       "    value {\n",
       "      cramers_v: 0.01589312144662912\n",
       "    }\n",
       "  }\n",
       "  stats_update_time {\n",
       "    seconds: 1575523334\n",
       "    nanos: 662000000\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first you'll need to make sure your model is predicting the right column\n",
    "tables_client.set_target_column(\n",
    "    dataset_display_name=DATASET_DISPLAY_NAME,\n",
    "    column_spec_display_name=TARGET_COLUMN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let our model know that input columns may have missing values\n",
    "for col in tables_client.list_column_specs(project=PROJECT_ID,\n",
    "                                           dataset_display_name=DATASET_DISPLAY_NAME):\n",
    "    if TARGET_COLUMN in col.display_name:\n",
    "        continue\n",
    "    tables_client.update_column_spec(project=PROJECT_ID,\n",
    "                                     dataset_display_name=DATASET_DISPLAY_NAME,\n",
    "                                     column_spec_display_name=col.display_name,\n",
    "                                     nullable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and then you'll need to kick off your model training\n",
    "response = tables_client.create_model(MODEL_DISPLAY_NAME, dataset_display_name=DATASET_DISPLAY_NAME, \n",
    "                                      train_budget_milli_node_hours=TRAIN_BUDGET, \n",
    "                                      exclude_column_spec_names=[TARGET_COLUMN])\n",
    "\n",
    "# check if it's done yet (it won't be)\n",
    "response.done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our model starts training, we don't need to do anything else: it's already saved in our GCP account and good to go for tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT\n",
    "\n",
    "Alright, now we'll move onto [TPOT](https://epistasislab.github.io/tpot/). This is an academic library built on top of scikit-learn, and my favorite thing about it is that when you export a model you're actually exporting all the Python code you need to train that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "347196bf-81e7-4114-8394-619a61278993",
    "_uuid": "e19d70b16755f4d338e27f17d4320dacf1fd9628",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94558b9c02e24950960c60517fe13492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=180, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.4962519650431746\n",
      "Generation 2 - Current best internal CV score: 0.4962519650431746\n",
      "\n",
      "The optimized pipeline was not improved after evaluating 2 more generations. Will end the optimization process.\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=0.1, max_depth=3, max_features=0.35000000000000003, min_samples_leaf=11, min_samples_split=18, n_estimators=100, subsample=0.6500000000000001)\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
      "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\n",
      "features = tpot_data.drop('target', axis=1).values\n",
      "training_features, testing_features, training_target, testing_target = \\\n",
      "            train_test_split(features, tpot_data['target'].values, random_state=None)\n",
      "\n",
      "# Average CV score on the training set was:0.4962519650431746\n",
      "exported_pipeline = GradientBoostingClassifier(learning_rate=0.1, max_depth=3, max_features=0.35000000000000003, min_samples_leaf=11, min_samples_split=18, n_estimators=100, subsample=0.6500000000000001)\n",
      "\n",
      "exported_pipeline.fit(training_features, training_target)\n",
      "results = exported_pipeline.predict(testing_features)\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "\n",
    "# create & fit TPOT classifier with \n",
    "tpot = TPOTClassifier(generations=8, population_size=20, \n",
    "                      verbosity=2, early_stop=2)\n",
    "tpot.fit(X_train_encoded, y_train_encoded)\n",
    "\n",
    "# save our model code\n",
    "tpot.export('tpot_pipeline.py')\n",
    "\n",
    "# print the model code to see what it says\n",
    "!cat tpot_pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H20.ai AutoML\n",
    "\n",
    "For our final model we'll be using [H20.ai's open source AutoML library](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html). One thing that I like about this library is that, as each model is trained, its evaluated both on its own and as part of a stacked ensemble. Kaggle competitors are very fond of stacking (and H20 is known for hiring a lot of top Kagglers) so it's nice to have that automated for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_232\"; OpenJDK Runtime Environment (build 1.8.0_232-8u232-b09-1~deb9u1-b09); OpenJDK 64-Bit Server VM (build 25.232-b09, mixed mode)\n",
      "  Starting server from /opt/conda/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpt4h02t2p\n",
      "  JVM stdout: /tmp/tmpt4h02t2p/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpt4h02t2p/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.26.0.8</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>1 month and 17 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_unknownUser_wh0ijv</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.26.0.8\n",
       "H2O cluster version age:    1 month and 17 days\n",
       "H2O cluster name:           H2O_from_python_unknownUser_wh0ijv\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.6.6 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# initilaize an H20 instance running locally\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# convert our data to h20Frame, an alternative to pandas datatables\n",
    "train_data = h2o.H2OFrame(X_train)\n",
    "test_data = h2o.H2OFrame(list(y_train))\n",
    "\n",
    "train_data = train_data.cbind(test_data)\n",
    "\n",
    "# Run AutoML for 20 base models (limited to 1 hour max runtime by default)\n",
    "aml = H2OAutoML(max_models=20, seed=1)\n",
    "aml.train(y=\"C1\", training_frame=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                          </th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GBM_5_AutoML_20191205_060406                      </td><td style=\"text-align: right;\">              0.680639</td><td style=\"text-align: right;\">  1.46891</td><td style=\"text-align: right;\">0.696247</td><td style=\"text-align: right;\">0.48476 </td></tr>\n",
       "<tr><td>XGBoost_1_AutoML_20191205_060406                  </td><td style=\"text-align: right;\">              0.681909</td><td style=\"text-align: right;\">  1.44647</td><td style=\"text-align: right;\">0.6996  </td><td style=\"text-align: right;\">0.489441</td></tr>\n",
       "<tr><td>DeepLearning_grid_1_AutoML_20191205_060406_model_1</td><td style=\"text-align: right;\">              0.682223</td><td style=\"text-align: right;\">  1.82753</td><td style=\"text-align: right;\">0.692592</td><td style=\"text-align: right;\">0.479684</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20191205_060406                      </td><td style=\"text-align: right;\">              0.682883</td><td style=\"text-align: right;\">  1.49003</td><td style=\"text-align: right;\">0.696902</td><td style=\"text-align: right;\">0.485673</td></tr>\n",
       "<tr><td>XGBoost_2_AutoML_20191205_060406                  </td><td style=\"text-align: right;\">              0.683375</td><td style=\"text-align: right;\">  1.46133</td><td style=\"text-align: right;\">0.7057  </td><td style=\"text-align: right;\">0.498013</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the top five models from the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=5)\n",
    "\n",
    "# The leader model can be access with `aml.leader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/GBM_5_AutoML_20191205_060406'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model out (we'll need to for tomorrow!)\n",
    "h2o.save_model(aml.leader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check that we've saved each of our models\n",
    "\n",
    "Before we wrap up for the day, we want to make sure we've saved all of our models for tomorrow! The Cloud AutoML model is saved automatically on GCP, but we've saved each of the other models in our current working directory. Let's just double check that that's the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_5_AutoML_20191205_060406  test_data_2018.csv   xgboost_baseline.model\n",
      "__notebook__.ipynb\t      tpot_pipeline.py\n",
      "__output__.json\t\t      train_data_2018.csv\n"
     ]
    }
   ],
   "source": [
    "# check to see that we've saved all of our models\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we've got three models and the code for the notebook. We're all set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Now it's your turn! Following the steps above, use the `df_2019` dataframe and: \n",
    "\n",
    "* Prepare your data (split into testing and training, encode variables)\n",
    "* Train your models: XGBoost, Cloud AutoML, TPOT and H20 AutoML\n",
    "\n",
    "> Note: if you can't or would prefer not to set up billing on order to use Cloud AutoML, feel free to skip training that model.\n",
    "\n",
    "* Remember to save your models! You'll need them tomorrow and, since it takes a while to run AutoML code, you don't want to have to run it multiple times.\n",
    "\n",
    "Have fun training your models and I'll see you all tomorrow for our final model evaluation!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d2665a041a24847a8a1107ccfb3c588": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5423454500a943f383e392e1328c2250": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "94558b9c02e24950960c60517fe13492": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cb280be79a7a4eff8d73e5b15c4e87a4",
        "IPY_MODEL_c80c80f7d76245daa596387fd3653948"
       ],
       "layout": "IPY_MODEL_9b46039dc28d48fb9164618eae47950f"
      }
     },
     "9b46039dc28d48fb9164618eae47950f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c80c80f7d76245daa596387fd3653948": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5423454500a943f383e392e1328c2250",
       "placeholder": "​",
       "style": "IPY_MODEL_fea2d37a5bdd44229615516cf0194379",
       "value": " 60/180 [14:49&lt;16:35,  8.29s/pipeline]"
      }
     },
     "cb280be79a7a4eff8d73e5b15c4e87a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "Optimization Progress:  33%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2d2665a041a24847a8a1107ccfb3c588",
       "max": 180,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e1dd7f4e64b74780a241652c8ab33e72",
       "value": 60
      }
     },
     "e1dd7f4e64b74780a241652c8ab33e72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "fea2d37a5bdd44229615516cf0194379": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
